# What is Azure Functions?
Azure Functions is a serverless solution that allows you to build robust apps while using less code, and with less infrastructure and lower costs. Instead of worrying about deploying and maintaining servers, you can use the cloud infrastructure to provide all the up-to-date resources needed to keep your applications running.

You focus on the code that matters most to you, in the most productive language for you, and Azure Functions handles the rest

## Scenarios
Functions provides a comprehensive set of event-driven [triggers and bindings](https://learn.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings) that connect your functions to other services without having to write extra code.

|If you want to...|then...|
|---|---|
|[Process file uploads](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#process-file-uploads)|Run code when a file is uploaded or changed in blob storage.|
|[Process data in real time](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#real-time-stream-and-event-processing)|Capture and transform data from event and IoT source streams on the way to storage.|
|[Run AI inference](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#machine-learning-and-ai)|Pull text from a queue and present it to various AI services for analysis and classification.|
|[Run scheduled task](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#run-scheduled-tasks)|Execute data clean-up code on predefined timed intervals.|
|[Build a scalable web API](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#build-a-scalable-web-api)|Implement a set of REST endpoints for your web applications using HTTP triggers.|
|[Build a serverless workflow](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#build-a-serverless-workflow)|Create an event-driven workflow from a series of functions using Durable Functions.|
|[Respond to database changes](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#respond-to-database-changes)|Run custom logic when a document is created or updated in a database.|
|[Create reliable message systems](https://learn.microsoft.com/en-us/azure/azure-functions/functions-scenarios#create-reliable-message-systems)|Process message queues using Azure Queue Storage, Service Bus, or Event Hubs.|


# Monitor executions in Azure Functions
Application Insights collects log, performance, and error data. By automatically detecting performance anomalies and featuring powerful analytics tools, you can more easily diagnose issues and better understand how your functions are used. These tools are designed to help you continuously improve performance and usability of your functions. You can even use Application Insights during local function app project development.

As Application Insights instrumentation is built into Azure Functions, you need a valid instrumentation key to connect your function app to an Application Insights resource. The instrumentation key is added to your application settings as you create your function app resource in Azure.

The [_host.json_ file](https://learn.microsoft.com/en-us/azure/azure-functions/functions-host-json) configuration determines how much logging a functions app sends to Application Insights.

### Dependencies
- Azure Cosmos DB
- Azure Event Hubs
- Azure Service Bus
- Azure Storage services (Blob, Queue, and Table)

Application Insights generates an _application map_ of collected dependency data.
Dependencies are written at the `Information` level. If you filter at `Warning` or above, you won't see the dependency data.

## Streaming Logs
There are two ways to view a stream of the log data being generated by your function executions.

- **Built-in log streaming**: the App Service platform lets you view a stream of your application log files. This stream is equivalent to the output seen when you debug your functions during [local development](https://learn.microsoft.com/en-us/azure/azure-functions/functions-develop-local) and when you use the **Test** tab in the portal. All log-based information is displayed. This streaming method supports only a single instance, and can't be used with an app running on Linux in a Consumption plan.
    
- **Live Metrics Stream**: when your function app is [connected to Application Insights](https://learn.microsoft.com/en-us/azure/azure-functions/configure-monitoring#enable-application-insights-integration), you can view log data and other metrics in near real time in the Azure portal using [Live Metrics Stream](https://learn.microsoft.com/en-us/azure/azure-monitor/app/live-stream). Use this method when monitoring functions running on multiple-instances or on Linux in a Consumption plan. This method uses [sampled data](https://learn.microsoft.com/en-us/azure/azure-functions/configure-monitoring#configure-sampling).

# Azure Functions triggers and bindings concepts
Binding to a function is a way of declaratively connecting your functions to other resources; bindings either pass data into your function (an _input binding_) or enable you to write data out from your function (an _output binding_) using _binding parameters_. Your function trigger is essentially a special type of input binding.

## Trigger and binding definitions
A function has a single trigger and one or more bindings. The type of binding is either input or output. Not all services support both input and output bindings.
Trigger and binding names are limited to alphanumeric characters and `_`, the underscore.

## Azure Functions custom handlers
Every Functions app is executed by a language-specific handler.
Custom handlers are lightweight web servers that receive events from the Functions host. Any language that supports HTTP primitives can implement a custom handler.

Custom handlers are best suited for situations where you want to:

- Implement a function app in a language that's not currently offered out-of-the box, such as Go or Rust.
- Implement a function app in a runtime that's not currently featured by default, such as Deno.

## Application structure

To implement a custom handler, you need the following aspects to your application:

- A _host.json_ file at the root of your app
- A _local.settings.json_ file at the root of your app
- A _function.json_ file for each function (inside a folder that matches the function name)
- A command, script, or executable, which runs a web server

### Configuration
The application is configured via the _host.json_ and _local.settings.json_ files.

#### host.json
_host.json_ tells the Functions host where to send requests by pointing to a web server capable of processing HTTP events.
A custom handler is defined by configuring the _host.json_ file with details on how to run the web server via the `customHandler` section.
```json
{
  "version": "2.0",
  "customHandler": {
    "description": {
      "defaultExecutablePath": "handler.exe"
    }
  }
}
```

The `customHandler` section points to a target as defined by the `defaultExecutablePath`. The execution target may either be a command, executable, or file where the web server is implemented.
Use the `arguments` array to pass any arguments to the executable. Arguments support expansion of environment variables (application settings) using `%%` notation

You can also change the working directory used by the executable with `workingDirectory`.

```json
{
  "version": "2.0",
  "customHandler": {
    "description": {
      "defaultExecutablePath": "app/handler.exe",
      "arguments": [
        "--database-connection-string",
        "%DATABASE_CONNECTION_STRING%"
      ],
      "workingDirectory": "app"
    }
  }
}
```

#### local.settings.json
_local.settings.json_ defines application settings used when running the function app locally. As it may contain secrets, _local.settings.json_ should be excluded from source control. In Azure, use application settings instead.

For custom handlers, set `FUNCTIONS_WORKER_RUNTIME` to `Custom` in _local.settings.json_.
```json
{
  "IsEncrypted": false,
  "Values": {
    "FUNCTIONS_WORKER_RUNTIME": "Custom"
  }
}
```

### Function metadata
When used with a custom handler, the _function.json_ contents are no different from how you would define a function under any other context. The only requirement is that _function.json_ files must be in a folder named to match the function name.

The following _function.json_ configures a function that has a queue trigger and a queue output binding. Because it's in a folder named _MyQueueFunction_, it defines a function named _MyQueueFunction_.

**MyQueueFunction/function.json**
```json
{
  "bindings": [
    {
      "name": "myQueueItem",
      "type": "queueTrigger",
      "direction": "in",
      "queueName": "messages-incoming",
      "connection": "AzureWebJobsStorage"
    },
    {
      "name": "$return",
      "type": "queue",
      "direction": "out",
      "queueName": "messages-outgoing",
      "connection": "AzureWebJobsStorage"
    }
  ]
}
```

# What are Durable Functions?
_Durable Functions_ is a feature of [Azure Functions](https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview) that lets you write stateful functions in a serverless compute environment. The extension lets you define stateful workflows by writing [_orchestrator functions_](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-orchestrations) and stateful entities by writing [_entity functions_](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-entities) using the Azure Functions programming model. Behind the scenes, the extension manages state, checkpoints, and restarts for you, allowing you to focus on your business logic.

## Application patterns

The primary use case for Durable Functions is simplifying complex, stateful coordination requirements in serverless applications. The following sections describe typical application patterns that can benefit from Durable Functions:

- [Function chaining](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=in-process%2Cnodejs-v3%2Cv1-model&pivots=csharp#chaining)
- [Fan-out/fan-in](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=in-process%2Cnodejs-v3%2Cv1-model&pivots=csharp#fan-in-out)
- [Async HTTP APIs](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=in-process%2Cnodejs-v3%2Cv1-model&pivots=csharp#async-http)
- [Monitoring](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=in-process%2Cnodejs-v3%2Cv1-model&pivots=csharp#monitoring)
- [Human interaction](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=in-process%2Cnodejs-v3%2Cv1-model&pivots=csharp#human)
- [Aggregator (stateful entities)](https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=in-process%2Cnodejs-v3%2Cv1-model&pivots=csharp#aggregator)

## Connections
Timer triggers have an implicit dependency on blob storage, except when run locally through the Azure Functions Core Tools. The system uses blob storage to coordinate across multiple instances [when the app scales out](https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-timer?tabs=python-v2%2Cisolated-process%2Cnodejs-v4&pivots=programming-language-csharp#scale-out). It accesses blob storage using the host storage (`AzureWebJobsStorage`) connection. If you configure the host storage to use an [identity-based connection](https://learn.microsoft.com/en-us/azure/azure-functions/functions-reference#connecting-to-host-storage-with-an-identity), the identity should have the [Storage Blob Data Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#storage-blob-data-owner) role, which is the default requirement for host storage.